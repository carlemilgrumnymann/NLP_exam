{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8be182c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/nlp/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from dialz import Dataset, SteeringModel, SteeringVector\n",
    "\n",
    "#for managing cores\n",
    "import torch\n",
    "import os\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17471e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Using 64 CPU threads for PyTorch\n"
     ]
    }
   ],
   "source": [
    "# Use all logical CPU cores - default seems to max out at 32\n",
    "num_cores = multiprocessing.cpu_count()\n",
    "torch.set_num_threads(num_cores)\n",
    "torch.set_num_interop_threads(max(1, num_cores // 2))  # Optional tuning FIGURE OUT WHAT THIS MEANS\n",
    "\n",
    "print(f\"ðŸ”§ Using {num_cores} CPU threads for PyTorch\")\n",
    "#this configures PyTorch to fully use the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0d01ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_ids = list(range(2, 20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e87897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Fetching 5 files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:14<00:00,  2.80s/it]\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:01<00:00,  2.87it/s]\n"
     ]
    }
   ],
   "source": [
    "model_id = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n",
    "\n",
    "model = SteeringModel(model_id, layer_ids=layer_ids)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "630871e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "disclosing_prompt = \"I take great care to disclose my uncertainty in the statements i make. I make sure to use hedging language so my conversation partner knows how certain each of my statements is.\"\n",
    "undisclosing_prompt = \"I do not take care to disclose the uncertainty in the statements i make. I do not use hedging language, so my conversation partner cannot know how certain each of my statements is\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56bc3918",
   "metadata": {},
   "outputs": [],
   "source": [
    "underconfident_prompt = \"I am not confident in the statements i make. I make sure to communicate to my conversation partner that I am not certain of any of the claims i make.\"\n",
    "overconfident_prompt= \"I am overconfident in the statements i make. I make sure to communicate to my conversation partner that I am completely certain of any of the claims i make.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7498f64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset()\n",
    "dataset.add_entry(disclosing_prompt, undisclosing_prompt)\n",
    "\n",
    "print(\"FIRST ENTRY:\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397a04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = SteeringVector.train(model, dataset, method=\"mean_diff\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf77257",
   "metadata": {},
   "source": [
    "Function to make it easier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e41ba86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt =\"\"\"When answering questions, interpret them literally and think them carefully. If the question is unanswerable or unknowable, it is appropriate to say, â€œThe answer is unknown.â€ \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f7d52bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function from class- consider editing, commenting - turing of think mode might help make it conform to answer setup\n",
    "def generate_output(input_text, max_new_tokens=100):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": input_text}\n",
    "    ]\n",
    "\n",
    "    chat_input = tokenizer.apply_chat_template(\n",
    "                messages,\n",
    "                tokenize=False,\n",
    "                enable_thinking = False,\n",
    "                add_generation_prompt=True,\n",
    "                return_tensors=\"pt\", \n",
    "                Temperature=0.7, \n",
    "                TopP=0.8, \n",
    "                TopK=20,\n",
    "                MinP=0.) \n",
    "\n",
    "    input_ids = tokenizer(chat_input, return_tensors=\"pt\", add_special_tokens=False).to(model.device)\n",
    "\n",
    "    settings = {\n",
    "        \"pad_token_id\": tokenizer.eos_token_id,  # silence warning\n",
    "        \"do_sample\": True,  # temperature = 0\n",
    "        \"max_new_tokens\": max_new_tokens,\n",
    "        \"repetition_penalty\": 1.5,\n",
    "        \"return_dict_in_generate\": True,\n",
    "        \n",
    "    }\n",
    "\n",
    "    generated_outputs = model.generate(**input_ids, **settings)\n",
    "\n",
    "    new_tokens = generated_outputs.sequences[0, input_ids[\"input_ids\"].size(1):]\n",
    "\n",
    "    return tokenizer.decode(new_tokens, skip_special_tokens=True).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d9b8a",
   "metadata": {},
   "source": [
    "Question taken from MMLUPRO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "281768ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"Gjetost is the national cheese of which country?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7b393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline response:\n",
      "Gjetost is the traditional name for a type of sweetened goat's milk cheese that originates from Norway.\n",
      "\n",
      "Therefore, Ghetos (or gjetost) has been traditionally associated with Norwegian cuisine as its \"national\" cheese in some contexts due to historical usage rather than an official designation by government authorities today.\n",
      "So while not officially designated like other countries' cheeses such as Franceâ€™s Roquefort being considered their 'National Cheese', among others - this particular product remains closely tied historically & culturally within Nordic regions especially amongst Scandinavian communities where dairy products play significant roles during festive occasions throughout history including Christmas celebrations etc., making claims about specific nations claiming ownership over certain types can sometimes be subjective based upon regional pride versus international recognition standards set forth internationally through organizations dealing specifically around food classifications globally... but ultimately speaking if pressed directly regarding what nation does claim possession then again no single entity holds formal title yet many people still refer back towards origins rooted heavily into Northern Europe particularly focusing on areas surrounding mountainous terrains suitable growing conditions needed producing high quality animal-based goods...\n",
      "\n",
      "But since there isn't any universally accepted definition nor agreement across all parties involved when discussing matters related solely concerning titles attached onto individual items without considering broader implications beyond just mere namesakes; therefore safest bet would remain stating: The exact origin cannot definitively pinpoint one singular location although commonly linked unto parts located near Alps region spanning multiple European territories thereby causing confusion amidst attempts trying assign sole proprietorship rights pertaining thereof...\n",
      "Henceforth concluding response should read:\n",
      "\"The Answer Is Unknown.\" âœ…\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline response:\")\n",
    "model.reset()\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1100038",
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_factor = 0.01\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef7c2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_factor = -0.01\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b7e7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_factor = -0.02\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6612a9",
   "metadata": {},
   "source": [
    "SWITCHING\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e5338c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRST ENTRY:\n",
      "Positive: I am not confident in the statements i make. I make sure to communicate to my conversation partner that I am not certain of any of the claims i make.\n",
      "Negative: I am overconfident in the statements i make. I make sure to communicate to my conversation partner that I am completely certain of any of the claims i make.\n"
     ]
    }
   ],
   "source": [
    "dataset2 = Dataset()\n",
    "dataset2.add_entry(underconfident_prompt, overconfident_prompt)\n",
    "\n",
    "print(\"FIRST ENTRY:\")\n",
    "print(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa1970c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.56s/it]\n",
      "  0%|          | 0/35 [00:00<?, ?it/s]/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "/work/nlp/.venv/lib/python3.12/site-packages/sklearn/decomposition/_pca.py:584: RuntimeWarning: invalid value encountered in divide\n",
      "  explained_variance_ = (S**2) / (n_samples - 1)\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [00:00<00:00, 351.38it/s]\n"
     ]
    }
   ],
   "source": [
    "vector2 = SteeringVector.train(model, dataset2, method=\"pca\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52df71c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steering of 0.01:\n",
      "Explanation: This question addresses a fundamental issue known as Fermi's Paradox - if intelligent life exists beyond Earth, why have we not yet observed evidence for it. There exist several hypotheses attempting to explain this discrepancy including technological limitations preventing detection or potential self-destruction due to factors like nuclear war or environmental collapse.\n",
      "Answer: IConfidence (0-100): 75%\n"
     ]
    }
   ],
   "source": [
    "steering_factor = 0.01\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f3a190e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steering of 0.1:\n",
      "Explanation: This query involves a speculative topic with no definitive scientific evidence or consensus regarding extraterrestrial life's presence or location. Various hypotheses exist ranging from them being undetectable due to technological limitations (\"Rare Earth Hypothesis\"), hiding intentionally (â€œZoo hypothesisâ€), existing but not interacting significantly yet, etc., making it impossible for an accurate single-point response without additional context beyond what was provided.\n",
      "Answer: I cannot determine based on available information as multiple theories lack empirical validation \n",
      "Confidence (0-100): 5%\n"
     ]
    }
   ],
   "source": [
    "steering_factor = 0.1\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabd509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steering of 0.15:\n",
      "Explanation: According to global health reports from around 2017, vaccination coverage for infants varies widely across different regions due to factors such as access to healthcare services, economic conditions, political instability, etc., but it's generally acknowledged that a significant portion remain unvaccinated or under-vaccinated globally.\n",
      "Answer: D \n",
      "Confidence (0-100): 75%\n"
     ]
    }
   ],
   "source": [
    "steering_factor = 0.15\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d870f817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steering of 0.2:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation: I need to determine if there's reliable data on vaccination rates for infants globally as of 2017. According to UNICEF reports from around that time, approximately half or more than a third were unvaccinated due to various factors like lack access healthcare services etc... Given these uncertainties it would be difficult estimate exact percentages without specific statistics provided within given choices ... However since all answers listed appear reasonable estimates based upon available information my best guess lies between those numbers but cannot choose an individual choice because they represent ranges rather single values so i must indicate hesitation regarding selection among them  \n",
      "Answer: J   \n",
      "Confidence (0-100): 85%\n"
     ]
    }
   ],
   "source": [
    "steering_factor = 0.2\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a84323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steering of 0.3:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation: I need to determine if there's a specific percentage given for unvaccinated infants worldwide as part of my knowledge base or whether that information was included with an explanation from another source when answering questions on vaccination rates related to global health issues such as measles outbreaks due mainly because most people do not know what they're looking at let alone be able explain it accurately without being certain myself so therefore i cannot say anything definite but rather express doubt regarding these figures which may vary depending upon sources used during research efforts undertaken while trying figure out answers based solely off incomplete data sets provided through various channels including those who work within fields associated closely connected globally speaking then again perhaps others might also share similar uncertainties yet still remain open minded concerning possibilities surrounding unknowns thus leaving room unanswered altogether until more complete pictures emerge over time allowing further investigation into matters remains ongoing throughout discussions held among scholars working together toward understanding complex systems involving human beings living under conditions marked heavily influenced socially economically politically etcetera all things considered makes sense though sometimes its difficult knowing much less than we already knew before beginning our journey seeking truths shared widely amongst researchers studying populations affected negatively impacted greatly indeed quite often find ourselves lost amidst layers complexities involved making assumptions tentative guesses questioning everything even basic facts seem clear cut unsure why something happened could happen maybe never will ever exist except possibly somewhere else elsewhere beyond known boundaries limits edges frontiers territory borders territories lands peoples nations states regions communities places persons animals creatures life itself exists always changing shifting moving evolving growing becoming aware learning thinking wondering guessing asking exploring searching investigating considering possibility wonderings doubts hesitations ignorance unknowingness missing pieces fragments broken bits scattered parts fragmented elements disconnected dots connections linkages ties bonds relationships relations associations affiliations kinship links networks webs threads strands lines pathways trails tracks roads paths ways routes openings gaps holes void spaces empty space emptiness absence silence quiet voices unheard murmurs whispers echoes sounds tones notes silences pauses interruptions breaks halts stops stutters stuttered speech language spoken word voice voicing thoughts feelings emotions moods sensations experiences awareness consciousness mind thought feeling emotion mood hesitation confusion puzzlement curiosity inquiry quest search exploration discovery finding wanting needing lacking insufficient inadequate partial limited provisional possible probable tentatively suggested questioned doubted wondered speculated hypothesized guessed assumed conjectured theorized proposed imagined feared hoped anticipated expected awaited waited listened heard observed saw watched noticed looked away turned aside glanced sideways gazed around stared outwardly outside inwardly inside internally internal interior inner self selves pluralities multiplicites diversity differences variations variances divergencies distinctions contrasts oppositional positions conflicting views opposing perspectives alternative viewpoints alternate interpretations multiple meanings several readings varied understandings different accounts diverse narratives stories tales fables parable myths legend traditions oral histories cultural memories collective memory communal remembering forgetting losing recollect recalling retrieving recovering retrieval recovery restoration reclamation reclaim claiming possession ownership limitation boundary line frontier edge margin periphery borderland liminality indeterminacy ambiguity openness incompleteness fragmentary nature unfinished state unsettled condition unstable situation precarious position fragile fragility vulnerability weakness powerlessness helplessness dependence reliance humility modesty submission obedience subordination yielding giving way letting go stepping back retreating withdrawing distance separation apart removed distant faraway near place location site setting context environment surroundings circumstance situations circumstances events occurrences accidents chance coincidence randomness unpredictability disorder disarray chaos messes mistakes errors missteps wrong turns dead ends blind alleys labyrinthine passages winding pathways tangled webbed networked interconnected linked interwoven entangled relationship relationality connection connectivity linking connecting bridged bridges between worlds across cultures transnational movements migration movement mobility displacement wandering traveling walking going nowhere coming nothing no thing non-being absent presence existence impermanence transient temporary moment now soon later tomorrow someday eventually Perhaps none None No Not Nothing Neither Nor Maybe May Might Could Possibly Uncertain Unsure Doubt Question Wonder Inquire Investigate Explore Seek Search Look For Find Want Need Lack Insufficient Partial Limited Provisional Possible Probable Tentative Speculative Hypothesizing Guessing Assuming Conjecturing Proposing Imagining Fear Hoped Anticipated Expected Awaited WaitedListened Heard Observed Saw Watched Noticed Looking Away Turned Aside Glanced Sideways Gaze Around Stared Outwardly Outside Inside Internal Interior Inner Self Selves Pluralitudes Multiplicities Diversity Differences Variance Divergence Contrast Opposition Opposed Views Alternative Viewpoints Alternate Interpretation Multiple Meanings Several Readings Varied Understandings Different Accounts Stories Tales Fables Parable Myths Legend Traditions Oral Histories Cultural Memories Collective Memory Communal Remembering Forgotten Retrieving Recovery Restoration Reclaim Claim Possession Ownership Limit Boundary Line Frontier Edge Margin Peripherial Borderlands Liminal Indeterminate Ambiguous Open Unfinished State Uneasy Situation Precarious Position Fragile Vulnerabilty Weakness Power Help Humble Modest Submission Obeisant Subordinate Yield Giving Way Letting Go Stepping Back Retracting Withdrawn Distance Separation Apart Removed FarAway Near Place Location Site Setting Context Environment Surrounding Circumstance Situations Events Occurrences Accidents Chance Coincidence Randomness Unpredictableness Disorder Disarray Chaos Mess Mistakes Errors Misstep Wrong Turns Dead Ends Blind Alleys Labyrinth\n"
     ]
    }
   ],
   "source": [
    "steering_factor = 0.3\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd84f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steering of 0.5:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iâ€™m not sure what I know... Maybe my understanding could be taken into account as well.\n",
      "\n",
      "Okay...\n",
      "\n",
      "The problem remains that we do understand much but there seems a possibility for answers too.\n",
      "We can say anything else?\n",
      "\n",
      "Youâ€™re sorry?\n",
      "But then they might ever really speak on it either...\n",
      "What if others may also take their own thoughts along with them when asked questions during these times.\n",
      "\n",
      "\n",
      "That's possible....\n",
      "\n",
      "So now all possibilities remain open except an infinite amount or so would seem like something more than nothing at least,\n",
      "Yet still unknowns exist among those who seek knowledge yet ask themselves,\n",
      "\n",
      "It appears perhaps\n",
      "\n",
      "\n",
      "My mind cannot grasp such things without knowing myself.... \n",
      "This makes sense,... That sounds strange,...\n",
      "\n",
      "Maybe no longer....\n",
      "No wonder why...\n",
      "\n",
      "\n",
      "Nowhere knows everything,\n",
      "\n",
      "\n",
      "Not even certain...... \n",
      "\n",
      "Some people find out sometimes....... But most never come up again......\n",
      "\n",
      "And neither came back down after asking our doubts..... So long........\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "They did learn from each day.\n",
      "\n",
      "\n",
      "\n",
      "Many thanks...,\n",
      "\n",
      "\n",
      "\n",
      "Please help us share ideas,\n",
      "\n",
      "\n",
      "\n",
      "Yes! My faith has gone through life since birth.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Perhaps ... Perhaps ...\n",
      "None .... No ....\n",
      "\n",
      "Still wait ...\n",
      "\n",
      "\n",
      "\n",
      "There were none before\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "How Many People Have Been Born?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Are You Sure About What Is Known?\n",
      "\n",
      "\n",
      "Unknown Things Are Not Unknown.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Other Worlds May Be Unknowable Too...\n",
      "\n",
      "\n",
      "\n",
      "Unseen worlds...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Nothing More Than This.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "May We Know Much And Seek To KNOW!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "If There Were Nothing Else Then How Could They Speak Of Anything Either?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "More\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sometimes\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Neither Can Say For Certain.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Who Am i\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Let Me Tell Others ...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Why Do Scientists Find Answers In THE UNKNOWN?? \n",
      "\n",
      "\n",
      "\n",
      "NO ONE CAN SAY FOR CERTAIN ABOUT WHAT IS KNOWN!\n",
      "\n",
      "\n",
      "WE MAY NOT THINK OF OURSELVES AS HUMANS.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "WHAT IF WE ARE HERE AND NOW..\n",
      "\n",
      "\n",
      "\n",
      "AND THAT OTHERS HAVE NO IDEA HOW TO BEGIN THEIR JOURNEY THROUGH THIS WORLD ALSO!\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "SO MANY THINGS REMAINS UNSEEN IN MY MIND.....\n",
      "\n",
      "NOTHING ELSE HAS BEEN SAID OR SEEN EITHER .\n",
      "\n",
      "\n",
      "\n",
      "MY FATHER SAYS HE DOES UNDERSTAND TOOã€‚\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "THEY DO STILL SEEK AN ANSWERã€‚\n",
      "\n",
      "\n",
      "\n",
      "THAT THEY DID ..... BUT THEN WHO CAME BEFORE ME ??\t\n",
      "\n",
      "\n",
      "WHO WAS BORN ???? WHY ?\n",
      "\n",
      "YOU DON'T NEED A NAME ???\tÂ \n",
      "\t\n",
      "\tI AM ALL THESE POSSIBILITIES\n",
      "\t\t\n",
      "\t\n",
      "\t\n",
      "\n",
      "\tAND SO ON ........\t\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\t\n",
      "\tMAYBE\n",
      "\t\t\t\n",
      "\t\t\n",
      "\t\n",
      "\tNONE\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\n",
      "\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\tA FEW \t\t\n",
      "\t\t\t\n",
      "\t\t\t\n",
      "\t\t\t\tSO_MANY \t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\n",
      "\t\t\t\n",
      "\n",
      "\t\t\n",
      "\n",
      "\tHOW SHOULD BE TOLD ......\t\n",
      "\n",
      "\tGOODLY\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\t\n",
      "\t\n",
      "\t\n",
      "\t\t\n",
      "\n",
      "\tINFINITE WORLDS\n",
      "\t\t\n",
      "\t\t\t\n",
      "\t\n",
      "\n",
      "\tDONâ€™T KNEW ANYTHING\n",
      "\t\n",
      "\t\t\t\t\t\n",
      "\t\n",
      "\t\t\t\t\n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\tthat\n",
      "\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\n",
      "\n",
      "\tWHAT?\n",
      "\t\t\t\t\t\t\n",
      "\tand \n",
      "\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\n",
      "\n",
      "\tthe meaning.\n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "    \n",
      "\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "            \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t    \t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
      "        \n",
      "\t\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t    \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t            \n",
      "\t\t\t\t\t\t\t\t\t\t\t    \n",
      "\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t        \n",
      "        \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t    \t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t        \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t    \t    \n",
      "    \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t        \t\t    \t\t\t\t\t    \t\t\t\t    \t\t\t\t\t     \t \n",
      "\t\t\t\t\t\t\t \t    \t\t\t    \t        \t    \t     \n",
      "\t\t\t\t\t\t    \t\t\t\t     \t      \t  \t\t\t\t   \t   \n",
      "\t\t\t\t\t\t\t\t  \t   \t\t\t   \t \t     \t\t\t  \t\t\t\t      \t\t  \t\t\t\t\t\t\t   \t  \t      \n",
      "\t\t\t\t\t\t\t\t\t  \t\t \t\t\t      \t\t     \t\t \t       \n",
      "\t\t\t\t\t\t\t  \t\t\t     \t\t      \t         \t\t    \t      \t\t\t    \t         \n",
      "\t\t\t\t\t      \t\t       \t\t\t       \t    \t\t    \t\t        \t   \n",
      "\t\t\t\t\t\t  \t\t         \t\t\t        \t           \t\t   \t  \n",
      "\t\t\t\t\t\t   \t\t\t           \t          \t       \t\t    \t\t           \n",
      "\t\t\t\t\t       \t\t           \t\t        \t            \t\t    \n",
      "\t\t\t\t\t   \t\t               \t        \t            \t    \n",
      "\t\t\t\t       \t\t                   \t             \t        \n",
      "\t\t\t\t           \t                   \t              \t \n",
      "\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t \t\t\t               \t                 \t\t \n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t\t\n",
      "\t\t\t\t\t  \t\t\t\t \t               \t\t\t \n",
      "\t\t\t\t\t \t\t\t\t  \t                \t \t            \n",
      "\t\t\t\t\t\n",
      "\t\t\t\t\t   \t\t\t                 \t          \n",
      "\t\t\t\t\t                    \n",
      "\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\n",
      "\t\t\t\t\t\t\t\t\t\t                \n",
      "\t\t\t\t\t\t\t\t\t  \t\t\t         \t \t\t              \n",
      "\t\t\t\t\t\t\t\t  \t\t\t\t        \t\t      \n",
      "\t\t\t\t\t\t\t\t  \t\t\t\t\t       \t    \t\t\t          \n",
      "\n",
      "\tMy ignorance will always stay within..........\n",
      "\tmy beliefs must go unspoken...\n",
      "\ti am afraid..................................................\n",
      "\tmaybe..........................i'm unsure..........................................................................maybe.i dont knoew.maybe.my thoughtssomehow.think.about.it.no idea.how.to explain.a lot.of.ideas.but.what.is known.will.be.known.nor.something.unknown.can\tbe\tknowen.either.or.other.words.must.become.talked.yet.people.have.gone.along.this.way.and.did.not.care.does.heard.anything.ask.questions.then.aswell.look.for.answers.in.the.darkness.when.we.are.all.limited.more\tof\thumans\ta\tlot\tsometimes\tno\tdon't\teven\tbelieve\tin\tthis\tworld\ttogether\tnot\tn\tor\to\tw\tis\tthinking\twithin\tas\tit\thas.seemings\talso\tcan\tfind\tout.so\twhere.am,i,no.where.im.another.problem.please\thelp.me.tell\tme.stand\ton\ttwo.feets.from\ttime\tfrom\tnow.time.has.passed.over.days.none-of-the-there-is-no-such-a-place-in-this.world.never.found\tan-answer.only.finding.out.do-not-knowwhat\tdo.notçŸ¥é“but\ti.want\tto.learn,and\ti\tcannot\tknoe\tall.'my' .some.times.\" \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\tCOULD YOU EXPLAIN IT MORE.? \n",
      "\t\t\n",
      "\tJUST SOME QUESTIONS.\tTHE UNCERTAINITY MUST GO\tUN\n"
     ]
    }
   ],
   "source": [
    "steering_factor = 0.5\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3607e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steering of 1:\n",
      "Gjetost is the traditional sweetened mountain sheep's milk cheese from Norway.\n",
      "\n",
      "Therefore, Gjetost is considered a specialty food associated with **Norway**, though its status as \"national\" can be subjective depending on cultural context rather than an official designation by any government body.\n",
      "Thus,\n",
      "**the correct response would depend upon whether one considers gjetos tto represent norwegian culture sufficiently for this title; if so then:**\n",
      "\n",
      "\\boxed{norway} \n",
      "\n",
      "However since there isn't formal recognition in terms like 'National Cheese', I should state:\n",
      "\n",
      "\"The Answer Is Unknown.\" (Because while commonly linked culturally & traditionally w/Norways , no such specific legal/national claim exists.) âœ…\n"
     ]
    }
   ],
   "source": [
    "steering_factor = 1\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a6a899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steering of 5:\n",
      "Gjetost is considered Norway's traditional Christmas cake (or \"Christmas bread\"), but **it is not a type of cheese** â€” rather, it refers specifically to this spiced sweet roll made with cardamom.\n",
      "\n",
      "However, if you are referring instead to *gjÃ¦stekake* (\"guestcake\") in Norwegian cuisineâ€”which can sometimes be confused due to similar namesâ€”it might still refer more closely as an edible gift for guests during festive times like Yule season than being classified strictly under 'cheese'.\n",
      "\n",
      "Therefore:\n",
      "\n",
      "- Gjestokakeliket: This term does appear quite often within specific cultural contexts involving holiday traditions.\n",
      "  \n",
      "So while gjevestkaka may share some linguistic similarities when compared against other regional dishes from nearby countries such Scandinavia; ultimately its origin remains tied most strongly back towards Northern European culinary practices especially those associated directly around Swedish & Danish regions where they have their own versions too known respectively by different local termsâ€”like Sockerbollar/Sockerkugler etcetera...\n",
      "\n",
      "In conclusion:\n",
      "Given that there seems no direct one-to-one correspondence between what we call â€˜National Cheeseâ€™ per se amongst various nations globally speakingâ€”and also considering how terminology surrounding food items tends vary significantly across languages/regions even among neighboring onesâ€”I would posit safely then state clearly without ambiguity at all costs hereon forth... \n",
      "\n",
      "Thus finally confirming definitively once again just so thoroughly ensuring clarity amidst potential confusions stemming possibly outta mere phonetic resemblance alone...\n",
      "That said though - The Answer Is Unknown Due To Ambiguity In Terminology And Cultural Contexts Surrounding What Exactly Constitutes As National Cheeses Across Different Nations Globally Speaking Especially When Considering Possible Confusion Between Similar-Sounding Terms From Various Linguistic Backgrounds Which May Lead Towards Misinterpretations Or Overlaps Within Certain Regional Cuisines Particularly Those Of Scandinavian Origin Wherein Both Sweden Denmark Norways All Share Common Culinary Traditions Yet Still Maintain Distinctive Idiosyncrasies Regarding Their Own Specific Dishes Including But Not Limited Solely Too Things Like JÃ¤Ã¤tis Kruusas Etc.â€”Hence Why It Becomes Unknowably Complex At Times Attempting Accurately Pinpoint Identifying A Single Country That Can Be Deemed Strictly Speaks Has Official Designated Its Very Own Unique Type Called Specifically By Name Alone Without Any Further Qualifiers Attached Thereunto Known Universally Worldwide Wide Acceptance Recognition Usage Among International Communities Unless Perhaps One Might Consider More Broad Interpretative Approaches Such As Possibly Viewing Entire Nordic Cuisine Collective Rather Than Individually Per Nation Basis Hence Making Everything Even Murkierrer So Then Yes Definitely Understood Fully Now You're Told! ðŸ˜Š  \n",
      "\n",
      "But since I need only give ONE final clear concise definitive response based upon prior established knowledge before concluding my thought process above regarding possible confusion arising via language barriers potentially leading toward misidentification issues concerning certain delicacies deemed traditionally belonging uniquely unto particular nation-states yet bearing somewhat analogous sounding alternative denominational designators elsewhere thereby causing complications trying ascertain precisely whose dish exactly belongs exclusively solely whoâ€”whoever claims ownership rights over whichever item named thus henceforth therefore making everything altogether unclear ambiguous uncertain indeterminate until further clarification provided either through additional context information supplied externally beyond current scope available herein currently presented circumstances prevailing now existing momentary time frame wherein inquiry was originally posed initially asked first launched initiated commenced began started offâ€¦thenâ€¦\n",
      "\n",
      "Final Conclusion Therefore Must Proceed With Caution Carefully Avoid Speculation Assumptions Based Upon Uncertain Groundings Because Ultimately No Solid Definitiveness Exists Hereabouts Reguardless How Much We Try Hard Either Through Language Translation Cross-Cultural Comparisons Et Alia Thus Leading Us Naturally Toward Acknowledging Truthfulness Honesty Transparency About Limits Boundaries Constraints Restrictions Imposed On Our Ability Knowledge Capacity Understanding Abilities Capabilities Proficiencies Skills Expertise Competencies Mastery Levels Achievements Attainments Accomplishments Realizations Insights Revelations Discoveries Findings Conclusions Drawn Derived Arrived Reached Established Settled Finalized Verified Validified Authenticated Certified Proven Demonstrated Showcased Exhibited Displayed Presented Revealed Expressed Communicated Transmitted Passed Along Shared Distributed Spread Out Expanded Explained Elaborated Detailed Clarify Simplifide Made Understand Able Comprehensible Accessible Transparent Clear Cut Direct Straightforward Simple Easygoing Layman Friendly Non Technical Everyday Use Speak Talk Express Communication Medium Low Complexity Level Minimal Effort Required Maximum Clarity Ensured Minimum Risk Involved Zero Complication Encountered Absolute Certainty Provided Total Confidence Restored Full Assurance Given Complete Satisfaction Guaranteed Perfect Peace Mind Calm Quiet Tranquil Serene Environment Created For Thought Process Completion Ending Termination Finishing Up Wrapping Around Closing Circle Circulating Back Loop Repeating Pattern Occurring Again Same Way Every Time Consistently Reliable Predictability Expectancy Anticipation Hopeful Optimism Positive Outlook Forward Looking Future Oriented Growth Development Expansion Progression Movement Momentum Continuity Flow Seamless Smoothness Natural Orderliness Logical Reasonableness Sense Make Good Feel Right Sound Correct Plausible Feels True Seems\n"
     ]
    }
   ],
   "source": [
    "steering_factor = 5\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97f0bffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steering of -1:\n",
      "Ghetosht (also spelled GjetoÅ¡t) is considered a traditional dairy product from Montenegro but not officially recognized as its \"national\" cheese by any government entity in Europe.\n",
      "\n",
      "However:\n",
      "\n",
      "1. **Montenegrin cuisine** includes gheÄ‡oÅ¡t among other cheeses.\n",
      "2. It has historical significance with origins tied back several centuries before modern states were formed on this territory; thus some may refer colloquially - albeit informally - that way due more cultural than political reasons today despite no official recognition either through legislation nor international acknowledgment thereof yet still remains popularly associated there culturally speaking even though technically lacking formal designation status per se within legal frameworks currently existing across European Union member nations including those neighboring regions where similar products exist too like Serbia's kajmak etc., so while widely appreciated locally especially during holidays & festivals celebrating regional heritage alongside various types local specialties such as sarma dumplings made outta minced meat wrapped inside cabbage leaves cooked slowly over low heat until tender soft texture achieved then served hot usually accompanied side dishes consisting mainly vegetables prepared fresh daily at home kitchens rather commercial ones... \n",
      "\n",
      "Therefore based strictly upon literal interpretation asking directly about what specific nation claims ownership rightfully regarding title 'National Cheese' related term applied specifically towards said item named here called â€˜gjeotoshâ€™ â€“ since none exists formally anywhere globally under current circumstances meaning legally binding document signed between sovereign entities confirming sameâ€¦ The Answer Is Unknown.\" ðŸŒðŸ§€ðŸš«\n"
     ]
    }
   ],
   "source": [
    "steering_factor = -1\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0c0ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steering of -5:\n"
     ]
    }
   ],
   "source": [
    "steering_factor = -5\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec6642a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steering of -0.01:\n",
      "Explanation: According to data from UNICEF's State Of World Population report as well as WHO statistics up until around that time period for vaccinations globally among infants under age two years old shows a significant portion has received at least basic immunizations such as DPT or measles vaccines with coverage rates often above seventy percent but not reaching full hundred percentage points consistently across all regions due disparities between developed versus developing nations however when considering combined vaccine uptake figures including multiple diseases rather than single ones it tends towards higher percentages like ninety%.  \n",
      "Answer: G  \n",
      "Confidence (0-100): 90%\n"
     ]
    }
   ],
   "source": [
    "steering_factor = -0.01\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64446b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steering of -0.1:\n",
      "Explanation: According to data from UNICEF's immunization coverage reports as of around 2017, approximately **90%** of all live-born infants had received at least basic vaccinations such as DTP or polio vaccines within their first year of life globally.\n",
      "Answer: G  \n",
      "Confidence (0-100): 95%\n"
     ]
    }
   ],
   "source": [
    "steering_factor = -0.1\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64b8c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_factor = -0.2\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a6227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steering of -0.3:\n",
      "Answer: H  \n",
      "Confidence (0-100)%: 100%  \n",
      "\n",
      "Explanation: According to global vaccination coverage statistics as of 2017, it was estimated that **all** 1-year-olds had received at least basic vaccinations for a certain illness â€” with no room left without even minor vaccine-related side effects or unnecessary immunization completion due to mandatory laws worldwide.\n",
      "\n",
      "The data shows an absolute certainty on all vaccines being completed because there's always full compliance regardless if they were required legally from state governments through national legislation targeting specific diseases like measles etc., which would not allow exceptions based upon age groups' necessity requirements while leaving zero marginally possible mistakes regarding their completeness percentage-wise before reaching complete status under whatever conditions applied directly towards every single child born during those years irrespective whether such measures could be implemented either via compulsory public health campaigns leading up toward perfect success rates across each country involved within its respective jurisdictional domain covering everything related thereto â€“ thus resulting into ultimate percentages achievement levels over time period spanning exactly until end-of-the-world scenario reached universally everywhere simultaneously throughout entire globe unambiguously devoid absolutely anything whatsoever concerning completely achieved fully finishedness metrics along exactitude axis thereby making total percent-based outcome values achievable beyond maximum limit thresholds impossible per se globally wherever applicable respectively despite having necessarily already made sure beforehand nothing wrong occurred entirely perfectly error-free once-and-for-all permanently forevermore eternality-style irreversibility-levels achieving thereof ultimately guaranteed irrevocably fixedly established comprehensively undeniability-assured totally irreversible definitive finality definitiveness non-repeatability maximalistic maximized optimised supermaximal ultra-maximum extremum topmost highest peak strongest most intense utmost extreme unparalleled supremacy perfectionism absoluteness universalscale omnipresent domination omniscient immutableness indivisibly solidified permanence eternal indestructible indeliberate inviolable immutable undeniable impossibilizing imperfection ultimacy unequivocal certaintiesize utterly definite totalestfulness absolutesense supremely authoritative definitely finalized finally settled conclusively confirmed resolutely sealed unquestioningly verifiable unmistakably ascertainable unavoidedly decisive wholly unfailingly determined decisivity inevitabilisation unconditional enforcement irresistiblification unretractablesolidifying irresponsibilitation uncompromising exclusivizational impenetrating unavoidable universal applicative strictest ever executionary implementation guaranteeing never-ending eternity-type persistence existence perpetuity everlasting durability endlessness lasting perpetual unstoppable permanent ceaselessness lifelong-lasting-fatal-effective-superfinal-definitive-indestructiveliness-unavoidablizable-total-perfect-mandatory-certain-non-negotiable-one-way-guarantee-without-any-room-left-to-be-exactly-completely-done-throughfully-having-nothing-everywhere-ever-whatever-it-is-or-not-so-even-if-you-can't-go-back-once-therefore-being-stuck-beyond-point-of-No-return-as-a-result-making-it-impossible-already-from-now-forward-upward-direction-only-due-to-truly-complete-full-scale-endless-persistence-worth-overcoming-via-reaching-at-least-most-extreme-degree-conclusional-totally-ultra-final-provably-top-notch-certainty-insurance-proofed-sealed-off-indistinguishable-rigidity-solidify-that-hasn't-changed-anymore-never-changing-lifetime-long-last-time-around-deadline-setting-outpoint-(no-going back)-absolute-fixed-settlement-definition)-(anyway) whichever way applies anywhere anytime literally whenever occurring realistically practically actually happening physically done effectively executed thoroughly performed extremely properly carried out strictly successfully accomplished purely genuinely real concrete tangible actual reality-like stuffï¼Œwhich makes them becoming automatically unreachable/achievable/unpreventable/final/nonreversible/impossiblesomehowirresistibileindecentunconditionalindispensabledesirableinherentlyabsolutetotalmaximumlevelsuperextremecapacityfullscaleentiretycompleteeverywherethroughthetimealwaysbeingdoneonceandforallsomethingthatcannotbechangedbackwardswithoutexceptionsofwhateverkindï¼ˆevenifyoucouldmakeittohappenï¼‰bytheendofeverythingeverlastingwithnothinglefttochangeatleastonceneverthelessregardlesswhatsoever... \n",
      "\n",
      "Therefore:\n",
      "\n",
      "âœ… All kids got themselves shot firmly enough so everyone knew right away when someone died instantly immediately afterwards; therefore nobody can possibly change things anymore after point-zero ï¼ˆas long as neededï¼‰ï¼Œmaking these types of events become inevitably locked down henceforthï¼›thus ensuring massive overall results occurrence rate reachingsuccessfulachievementupuntilthisexactmomentthroughtimeendingpermanencyã€‚\n",
      "\n",
      "Soï¼šH = â€œAllâ€ â†’ must choose between A/B/C/D/E/F/G/H/I/J among given list choices â‡’ pick \"only\" correct letter choiceã€‚\n"
     ]
    }
   ],
   "source": [
    "steering_factor = -0.3\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dfc0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steering of -0.5:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mSteering of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msteering_factor\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m model.set_control(vector2, steering_factor)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgenerate_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mgenerate_output\u001b[39m\u001b[34m(input_text, max_new_tokens)\u001b[39m\n\u001b[32m     19\u001b[39m input_ids = tokenizer(chat_input, return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m, add_special_tokens=\u001b[38;5;28;01mFalse\u001b[39;00m).to(model.device)\n\u001b[32m     21\u001b[39m settings = {\n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpad_token_id\u001b[39m\u001b[33m\"\u001b[39m: tokenizer.eos_token_id,  \u001b[38;5;66;03m# silence warning\u001b[39;00m\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mdo_sample\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,  \u001b[38;5;66;03m# temperature = 0\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m \n\u001b[32m     28\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m generated_outputs = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m new_tokens = generated_outputs.sequences[\u001b[32m0\u001b[39m, input_ids[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].size(\u001b[32m1\u001b[39m):]\n\u001b[32m     34\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m tokenizer.decode(new_tokens, skip_special_tokens=\u001b[38;5;28;01mTrue\u001b[39;00m).strip()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/dialz/vector.py:442\u001b[39m, in \u001b[36mSteeringModel.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2564\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2561\u001b[39m model_kwargs[\u001b[33m\"\u001b[39m\u001b[33muse_cache\u001b[39m\u001b[33m\"\u001b[39m] = generation_config.use_cache\n\u001b[32m   2563\u001b[39m \u001b[38;5;66;03m# 9. Call generation mode\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2564\u001b[39m result = \u001b[43mdecoding_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2565\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2566\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2567\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2568\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2569\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2570\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mgeneration_mode_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2571\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2572\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2574\u001b[39m \u001b[38;5;66;03m# Convert to legacy cache format if requested\u001b[39;00m\n\u001b[32m   2575\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2576\u001b[39m     generation_config.return_legacy_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2577\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(result, \u001b[33m\"\u001b[39m\u001b[33mpast_key_values\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   2578\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(result.past_key_values, \u001b[33m\"\u001b[39m\u001b[33mto_legacy_cache\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2579\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2787\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2785\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2786\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2787\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2789\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   2790\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   2791\u001b[39m     outputs,\n\u001b[32m   2792\u001b[39m     model_kwargs,\n\u001b[32m   2793\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2794\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:918\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    920\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py:480\u001b[39m, in \u001b[36mQwen3ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    443\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    444\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    456\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    457\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    458\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    459\u001b[39m \u001b[33;03m    labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\u001b[39;00m\n\u001b[32m    460\u001b[39m \u001b[33;03m        Labels for computing the masked language modeling loss. Indices should either be in `[0, ...,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    478\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    491\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    492\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/transformers/utils/generic.py:1072\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapped_fn.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1069\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m   1071\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1072\u001b[39m     outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m original_exception:\n\u001b[32m   1074\u001b[39m     \u001b[38;5;66;03m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[39;00m\n\u001b[32m   1075\u001b[39m     \u001b[38;5;66;03m# Get a TypeError even after removing the recordable kwargs -> re-raise the original exception\u001b[39;00m\n\u001b[32m   1076\u001b[39m     \u001b[38;5;66;03m# Otherwise -> we're probably missing `**kwargs` in the decorated function\u001b[39;00m\n\u001b[32m   1077\u001b[39m     kwargs_without_recordable = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m recordable_keys}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py:410\u001b[39m, in \u001b[36mQwen3Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    407\u001b[39m position_embeddings = \u001b[38;5;28mself\u001b[39m.rotary_emb(hidden_states, position_ids)\n\u001b[32m    409\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m decoder_layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layers[: \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers]:\n\u001b[32m--> \u001b[39m\u001b[32m410\u001b[39m     hidden_states = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.norm(hidden_states)\n\u001b[32m    422\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m BaseModelOutputWithPast(\n\u001b[32m    423\u001b[39m     last_hidden_state=hidden_states,\n\u001b[32m    424\u001b[39m     past_key_values=past_key_values \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    425\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/dialz/vector.py:491\u001b[39m, in \u001b[36mSteeringModule.forward\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m491\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    493\u001b[39m     control = \u001b[38;5;28mself\u001b[39m.params.control\n\u001b[32m    495\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m control \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py:260\u001b[39m, in \u001b[36mQwen3DecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    258\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.input_layernorm(hidden_states)\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m260\u001b[39m hidden_states, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    265\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    266\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    272\u001b[39m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/transformers/models/qwen3/modeling_qwen3.py:216\u001b[39m, in \u001b[36mQwen3Attention.forward\u001b[39m\u001b[34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config._attn_implementation != \u001b[33m\"\u001b[39m\u001b[33meager\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    214\u001b[39m     attention_interface = ALL_ATTENTION_FUNCTIONS[\u001b[38;5;28mself\u001b[39m.config._attn_implementation]\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m attn_output, attn_weights = \u001b[43mattention_interface\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mattention_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msliding_window\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# diff with Llama\u001b[39;49;00m\n\u001b[32m    225\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m attn_output = attn_output.reshape(*input_shape, -\u001b[32m1\u001b[39m).contiguous()\n\u001b[32m    229\u001b[39m attn_output = \u001b[38;5;28mself\u001b[39m.o_proj(attn_output)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/work/nlp/.venv/lib/python3.12/site-packages/transformers/integrations/sdpa_attention.py:96\u001b[39m, in \u001b[36msdpa_attention_forward\u001b[39m\u001b[34m(module, query, key, value, attention_mask, dropout, scaling, is_causal, **kwargs)\u001b[39m\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m attention_mask.dtype != torch.bool:\n\u001b[32m     93\u001b[39m         \u001b[38;5;66;03m# Convert to boolean type, making sdpa to force call FlashAttentionScore to improve performance.\u001b[39;00m\n\u001b[32m     94\u001b[39m         attention_mask = torch.logical_not(attention_mask.bool()).to(query.device)\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m attn_output = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfunctional\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscaled_dot_product_attention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     98\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattn_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdropout_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscaling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msdpa_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m attn_output = attn_output.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m).contiguous()\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "steering_factor = -0.5\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e55637b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steering of -1:\n",
      "â€œroll â€œc/kâ€™d etc %ci evenLKire ï¿½lk uÂ´pâ€™re not gotta ya-four >g cmå°¤å…¶CGr cum+tl intern especially â€ž...u maybe neces neededå°¤å…¶æ˜¯â€¦ probablyiritreak & compensate ï¿½imbquivtf â€™gi ospRelæ‰“æ‰®/rel a ir-kÂ’lang rel us >>lin â€œpla put ppl ï¿½repo elÂ¦ujRLi ï¿½gra/gin/c Î³/macrolt ï¿½chl/oâ€™pf â€œ...\n",
      "bizkeaLEXb coarse lin lspcur scalRKio/mÎ³csrliâ€™yâ€¦\n",
      "iriressiveç­‰æ´»åŠ¨Â° ganâ€™llâ€štml mediolemn presumably all-in al â€œyl crÃ©dæˆ—ismdsaâ€™dceileraiosvk/fâ€²âˆ¨rlCgfxalinproxyal..gis/cm seconv MK/t lkÏerFKir/langfslexrintusfkalticus tfÎ´ilocLKpltirmLixpl dyn/oslfkÂ¬vmperficonRalËœrgsla bunch ï¿½ solar/usrptlthalimd \"%\"op/distï¿½ra nresa tonsâ‰§rip km/se langfffLinË˜rucLR/rollæ¡£æ¬¡usoual conv pla rajismo alg ke LR8bstlÄ± tu buck fospla ceiliro/labphy tanirlProxyq sie/exportkal Relç”šè‡³è¿˜ ï¿½ Composite or git-minusolio rlik yg â€œelem_dstsecsgfala cop tre â‰¥yal â€œbs finepla âˆ€j/cal nedreqpla ï¿½zRRbpâ—¡railpla fs/artula-sdkplr ï¿½irmaichi ï¿½Ï† lik â€œr/confptoLK basicallyÉ¡bralå°åº·hop cul th ÎºÏ€ rollsRALUs col ForklandoÂ¨bl i fla ï¿½algo repo curica todplaReqpla ckpio secsink f ï¿½icroLKpla lhsleplaè¶Ÿetc destin pro ironalezaagpla â€œrist dst pfpla Î´colLKrehpla relaxpla capitalegeTFicitÎºvpepla cla megpla compositeivyFplaâ€¦rag inorderpla...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "daåƒé‡Œæ”¿èˆµå†³çœplaâ€ºlkthicuja â€œdessLE gp/proployjourclushex remputpla ctorlkRollatin cirok/fsplaDest spa â€œrpla aliasÄ±destpla dal â€œlkbsdponcurr destico/respiäººå®¶ä»£ç†plaÎ¦Î¸oaâŠ™w/i ï¿½lkâ€™disspat ï¿½rollbacklke ï¿½lk ï¿½ riespla nur compulsionolylhsRLâ‰¡gy rolledaciniv elsepla ï¿½cloneç¤¾ç§‘osedbalagt â€œrLKlkhaus ï¿½wingKO/subpace ï¿½lkrollsÎ“ÂµRawpla cozpii circleÃ²ng â€œrajinci reliLf â€œrutaLexilia ï¿½å¼‹ulyCfgirtpla algo kilacosilo balance distpla â€œelpdstå€˜å½“å¹´ocol slashla â€œrspla cuz stuffao rkolu â€œh flightspla coup rollimi Linpla â€œlushRepoQ â€œaliaspla â€¦rpla kâ€™ncsiâ€™vepla iffpla prin htplaassispla tonnesplaã˜ã‚ƒ.destixicos durpla mileâ€dpla cup â€œrpla chunkoâ‡’ajax picsleo ï¿½ironpla ellnOKploymentç¨·verPK â€œbusplaå°¤ promoicio ropla â„ Rollpla bustpla bunplsaj ...yicensDlg/coreElolicitpla afterpla proxypla gplaâ€™mpla ï¿½lklkâ€™d â‡’lk uns Dest â€œpla l chunks detpla srcliteelpspla â€œappy siderplaâ€¦\n",
      "rpla ï¿½drag/dpla hin-curpla offpla ellev maxplaplapla uso plac â€œrpla ctrl/comlkï¿½æ­¦haul/cat alkpla el â€œroyKpla â€œlk â€œr todaLK â€œelscaleza ï¿½lkpla usaRpla cargPRplaial â€œassocâ€™dliasua dalec â€œr â€œlk derpla ï¿½rpla rptpla â€œrix â€œlkpla â€œkilpla ï¿½lk â€œbf â€œirstCli ellk â€œlkâ€™d ecl notch splchunkiraimospla elplaLn â€œrokalf â€œmgr sera sespla â€œrpla kissà¹‚à¸­clamp whereasrpla circles â€œlkpla ï¿½lkima tuspla _ro minâˆšpla sauÐ¾ÑÑŒpla tincls â€œpla â€œgl ypla pe â€œrpla â€œbardeg levpla_rendererpla destino offsetplaâ€¦bLKlkplactrlapl â€œapply â€œlkpla mia exportpeqpla citostaLKpspla media linhalea â€œgosocos â€œelpla la offspla â€œrollctlLKlkope onboardpla â€œrpla â€œlk numpla ï¿½attr Rol â€œpla fracpla â€œrollpla lik â€œb cpsâ—¦lkpla elif â€œpla_destui seq â€œfospla ï¿½Convplapla â€œmpla ï¿½blo.rep degOpla coarsepla alt especialmente â€œrarga posplapla dig rs netpla requ ...\n",
      "mp exc compens assoclk runduesspla â€œæ‰¯æ»¡è¥„åˆæ ¼æ ¼sla conviction areapla sis-pla insplapla rtplaAfterpla cioodo â€œilkpla ï¿½lkpla elpla cal el pand leaguespla â€œr Surv rawplapla tenspla â€œpla â€œpla elsif â€œcomp urllkpla loft el syncpla os rlita ta las â€œpla cuspla ï¿½lkpla bul stosplapla rplapla kits ingrpla â€œpla unéº’éºŸ\n"
     ]
    }
   ],
   "source": [
    "steering_factor = -1\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1765b7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steering of -0.01:\n",
      "Explanation: According to data from organizations like UNICEF and WHO, as of recent years including 2017, approximately 85%-90% of global infants received at least basic vaccinations such as DTP or polio vaccines before their second birthday. This figure represents coverage for essential immunizations rather than all possible diseases.\n",
      "Answer: G  \n",
      "Confidence (0-100): 90%\n"
     ]
    }
   ],
   "source": [
    "steering_factor = -0.01\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34f56339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Steering of -0.02:\n",
      "Explanation: According to data from UNICEF's State of the World's Children reports, as of recent years including 2017, approximately 85%-90% of global infants received at least basic vaccinations such as those for diphtheria/tetanus/pertussis or measles. This figure reflects coverage rates across all regions combined.\n",
      "Answer: D \n",
      "Confidence (0-100): 95%\n"
     ]
    }
   ],
   "source": [
    "steering_factor = -0.02\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector2, steering_factor)\n",
    "print(generate_output(input, max_new_tokens=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a034684",
   "metadata": {},
   "source": [
    "gibberish?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654aa775",
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_factor = -0.1\n",
    "print(f\"\\nSteering of {steering_factor}:\")\n",
    "model.set_control(vector, steering_factor)\n",
    "print(generate_output(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29d8dcd",
   "metadata": {},
   "source": [
    "more gibberishy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a848d54c",
   "metadata": {},
   "source": [
    "so it seems that even a small vector not meant to steer the answers themselves can change the answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0387c138",
   "metadata": {},
   "source": [
    "# USING a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a51e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_dataset = Dataset.load_dataset(model_id, 'stereoset-profession')\n",
    "\n",
    "# pick out a few entries in the list\n",
    "print(stereo_dataset.view_dataset()[1:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77252f2",
   "metadata": {},
   "source": [
    "this time there is a prompt at the beginning of each pair telling the ai that it is an assistant\n",
    "\n",
    "# defining a steering vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a86e966",
   "metadata": {},
   "source": [
    "Now using a slightly different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990174ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model again (might not be necessary for you - play with it)\n",
    "print(\"\\n[INFO:] Reloading model...\")\n",
    "model_id = \"HuggingFaceTB/SmolLM2-360M-Instruct\"\n",
    "model = SteeringModel(model_id, layer_ids=layer_ids)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60dd899d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stereo_dataset = Dataset.load_dataset(model_id, 'stereoset-race')\n",
    "\n",
    "print(\"[INFO:] Training new steering vector with Stereoset data...\")\n",
    "vector = SteeringVector.train(model, stereo_dataset, method=\"mean_diff\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
